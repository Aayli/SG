{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a33536a-acfd-42b7-b77d-8316a76f00a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 19:36:18.413078: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-03 19:36:18.413132: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "from matplotlib import pyplot\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d84ae3b-93cd-43e1-9e3a-27d71cb088a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"eight\", \"four\", \"five\", \"three\", \"six\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "320d30b4-1045-49f5-a027-edf15104dca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eight\n",
      "four\n",
      "five\n",
      "three\n",
      "six\n"
     ]
    }
   ],
   "source": [
    "train_audio_path = '/home/wojtek/SG/speech_classification/'\n",
    "\n",
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves[:800]:\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
    "        samples = librosa.resample(samples, sample_rate, 8000)\n",
    "        if(len(samples)== 8000): \n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b4ec9b-fa5a-40b6-b62b-183751b5fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y=le.fit_transform(all_label)\n",
    "classes= list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ef14c7-3e39-42a9-9721-c308fc34a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np_utils.to_categorical(y, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1215ebd4-bfef-4582-9d0c-919122bfc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4e9536-a977-44ac-8401-ce497e3f3839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fda870b0-a7bc-4cd6-af47-a9a07d66d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate(sound, speed_factor):\n",
    "    return librosa.effects.time_stretch(sound, speed_factor)\n",
    "\n",
    "def manipulate2(sound, sound_rate, n_steps):\n",
    "    return librosa.effects.pitch_shift(sound, sound_rate, n_steps)\n",
    "\n",
    "@tf.function\n",
    "def data_augmentation_sound(sound, p=0.5):\n",
    "    if tf.random.uniform([])<p:\n",
    "        sound = sound + 0.9*np.random.normal(0,1,8000)\n",
    "        #manipulate(sound, 0.8)\n",
    "        #manipulate2(sound, 8000, -3)\n",
    "        print(\"dziala\")\n",
    "    else:\n",
    "        sound\n",
    "    #sound = tf.reshape(sound, (None,8000,1))\n",
    "    #sound = tf.expand_dims(sound, 1)\n",
    "    return sound\n",
    "\n",
    "def data_augmentation(factor=0.5):\n",
    "    return keras.layers.Lambda(lambda x: data_augmentation_sound(x, factor))\n",
    "\n",
    "data_augmentation = data_augmentation()\n",
    "\n",
    "class RandomAugmentation(keras.layers.Layer):\n",
    "    def __init__(self, factor=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.factor = factor\n",
    "        \n",
    "    def call(self, x):\n",
    "        return data_augmentation_sound(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129289ff-74e3-4414-b75f-2dd65934b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(audio, model):\n",
    "    indices = np.empty(len(y_valid))\n",
    "    e = 0\n",
    "    for i in audio:\n",
    "        prob=model.predict(i.reshape(-1,8000,1))\n",
    "        index=np.argmax(prob[0])\n",
    "        indices[e]=index\n",
    "        e += 1\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c1375a9-f222-42b1-a3c6-135c4c52ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 19:37:29.655312: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-03 19:37:29.655359: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-03 19:37:29.655387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wojtek): /proc/driver/nvidia/version does not exist\n",
      "2021-11-03 19:37:29.655604: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-03 19:37:29.773725: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 104480000 exceeds 10% of free system memory.\n",
      "2021-11-03 19:37:29.928939: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Macierz pomylek: \n",
      "\n",
      "[[ 3  0  0 35 33]\n",
      " [ 0 39 19  9  6]\n",
      " [ 1  3 13 35 21]\n",
      " [ 1  0  1 52 20]\n",
      " [ 2  1  0 40 29]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 19:38:25.557571: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 104480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Macierz pomylek: \n",
      "\n",
      "[[20  0  0 34 17]\n",
      " [ 0 55 13  2  3]\n",
      " [ 1  1 62  9  0]\n",
      " [ 8  0  1 52 13]\n",
      " [ 5  0  1 36 30]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 19:39:21.307551: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 104480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Macierz pomylek: \n",
      "\n",
      "[[19  0  0 46  6]\n",
      " [ 0 40 29  2  2]\n",
      " [ 0  4 58 10  1]\n",
      " [ 6  0  3 58  7]\n",
      " [ 4  1  1 43 23]]\n",
      "\n",
      "Precyzja: [0.459927235963978, 0.6485481752509618, 0.6271894808004111]\n",
      "\n",
      "Pelnosc: [0.37201255374610576, 0.6007598472483673, 0.5426599230911405]\n",
      "\n",
      "F1: [0.3479103347526187, 0.6014384258590528, 0.5355103333066559]\n",
      "\n",
      "Srednia precyzja dla 10 prob: 0.578554964005117\n",
      "\n",
      "Srednia pelnosc dla 10 prob: 0.5051441080285378\n",
      "\n",
      "Srednie F1 dla 10 prob: 0.4949530313061092\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.1,random_state=777,shuffle=True)\n",
    "\n",
    "precision_summary =[]\n",
    "recall_summary = []\n",
    "f1_summary = []\n",
    "for i in range(3):\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(8000,1))\n",
    "    #First Conv1D layer\n",
    "    conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Second Conv1D layer\n",
    "    conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Third Conv1D layer\n",
    "    conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Fourth Conv1D layer\n",
    "    conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Flatten layer\n",
    "    conv = Flatten()(conv)\n",
    "    #Dense Layer 1\n",
    "    conv = Dense(256, activation='relu')(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Dense Layer 2\n",
    "    conv = Dense(128, activation='relu')(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    outputs = Dense(len(labels), activation='softmax')(conv)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    #model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train ,epochs=3, verbose=0, callbacks=[es,mc], batch_size=32, validation_data=(x_valid,y_valid))\n",
    "    y_pred = predict(x_valid, model)\n",
    "    y_valid_max = np.argmax(y_valid, axis=1)\n",
    "    confmat = confusion_matrix(y_true=y_valid_max, y_pred=y_pred)\n",
    "    print(\"\\n\\nMacierz pomylek: \\n\\n{}\".format(confmat))\n",
    "\n",
    "    precision_macro = precision_score(y_true=y_valid_max, y_pred=y_pred, average='macro')\n",
    "    precision_summary.append(precision_macro)\n",
    "    recall_macro = recall_score(y_true=y_valid_max, y_pred=y_pred, average='macro')\n",
    "    recall_summary.append(recall_macro)\n",
    "    f1_macro = f1_score(y_true=y_valid_max, y_pred=y_pred, average='macro')\n",
    "    f1_summary.append(f1_macro)\n",
    "precision_avg = sum(precision_summary)/len(precision_summary)\n",
    "recall_avg = sum(recall_summary)/len(recall_summary)\n",
    "f1_avg = sum(f1_summary)/len(f1_summary)\n",
    "print(\"\\nPrecyzja: {}\".format(precision_summary))\n",
    "print(\"\\nPelnosc: {}\".format(recall_summary))\n",
    "print(\"\\nF1: {}\".format(f1_summary))\n",
    "print(\"\\nSrednia precyzja dla 10 prob: {}\".format(precision_avg))\n",
    "print(\"\\nSrednia pelnosc dla 10 prob: {}\".format(recall_avg))\n",
    "print(\"\\nSrednie F1 dla 10 prob: {}\".format(f1_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "327c414f-7ecf-4258-a670-be893747bfe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The channel dimension of the inputs should be defined. Found `None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113456/3901587032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#First Conv1D layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0minput_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_input_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_channel\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/envs/SG/lib/python3.7/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m_get_input_channel\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mchannel_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_channel_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m       raise ValueError('The channel dimension of the inputs '\n\u001b[0m\u001b[1;32m    367\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The channel dimension of the inputs should be defined. Found `None`."
     ]
    }
   ],
   "source": [
    "precision_summary =[]\n",
    "recall_summary = []\n",
    "f1_summary = []\n",
    "for i in range(3):\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(8000,1))\n",
    "    conv = data_augmentation(inputs)\n",
    "    #First Conv1D layer\n",
    "    conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(conv)\n",
    "    #conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Second Conv1D layer\n",
    "    conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Third Conv1D layer\n",
    "    conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Fourth Conv1D layer\n",
    "    conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Flatten layer\n",
    "    conv = Flatten()(conv)\n",
    "    #Dense Layer 1\n",
    "    conv = Dense(256, activation='relu')(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    #Dense Layer 2\n",
    "    conv = Dense(128, activation='relu')(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    outputs = Dense(len(labels), activation='softmax')(conv)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train ,epochs=3, verbose=0, callbacks=[es,mc], batch_size=32, validation_data=(x_valid,y_valid))\n",
    "    y_pred = predict(x_valid, model)\n",
    "    y_valid_max = np.argmax(y_valid, axis=1)\n",
    "    confmat = confusion_matrix(y_true=y_valid_max, y_pred=y_pred)\n",
    "    print(\"\\n\\nMacierz pomylek: \\n\\n{}\".format(confmat))\n",
    "\n",
    "    precision_macro = precision_score(y_true=y_valid_max, y_pred=y_pred, average='macro')\n",
    "    precision_summary.append(precision_macro)\n",
    "    recall_macro = recall_score(y_true=y_valid_max, y_pred=y_pred, average='macro')\n",
    "    recall_summary.append(recall_macro)\n",
    "    f1_macro = f1_score(y_true=y_valid_max, y_pred=y_pred, average='macro')\n",
    "    f1_summary.append(f1_macro)\n",
    "precision_avg = sum(precision_summary)/len(precision_summary)\n",
    "recall_avg = sum(recall_summary)/len(recall_summary)\n",
    "f1_avg = sum(f1_summary)/len(f1_summary)\n",
    "print(\"\\nPrecyzja: {}\".format(precision_summary))\n",
    "print(\"\\nPelnosc: {}\".format(recall_summary))\n",
    "print(\"\\nF1: {}\".format(f1_summary))\n",
    "print(\"\\nSrednia precyzja dla 10 prob: {}\".format(precision_avg))\n",
    "print(\"\\nSrednia pelnosc dla 10 prob: {}\".format(recall_avg))\n",
    "print(\"\\nSrednie F1 dla 10 prob: {}\".format(f1_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8a3bc-a2d5-440e-99ae-6f813ccb9f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
