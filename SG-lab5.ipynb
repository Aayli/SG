{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celem ćwiczenia jest prezentacja możliwości wykorzystania metod uczenia maszynowego\n",
    "w rozpoznawaniu komend głosowych.\n",
    "\n",
    "Materiałem użytym w ćwiczeniu będą próbki nagrań komend z poprzednich ćwiczeń.\n",
    "Przypomnijmy, w zbiorze jest:\n",
    "- 30 (+szum) komend,\n",
    "- nagranych ok. 1,7-2,4 tys. razy.\n",
    "\n",
    "Treścią zadania jest klasyfikacja komend:\n",
    "- klasa (class) = komenda,\n",
    "- próbka (sample) = nagranie.\n",
    "\n",
    "Ćwiczenie podzielone jest na cztery etapy:\n",
    "1. Ekstrakcja cech z próbek\n",
    "2. Podział próbek na treningowe i testowe\n",
    "3. Uczenie klasyfikatora\n",
    "4. Klasyfikacja nieznanej próbki\n",
    "5. Ocena działania klasyfikatora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bibliotek\n",
    "import os\n",
    "import librosa\n",
    "import pickle\n",
    "import sklearn\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal N_MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_mfcc=1 \t Ocena klasyfikatora: 2.67 %\n",
      "n_mfcc=2 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=3 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=4 \t Ocena klasyfikatora: 6.00 %\n",
      "n_mfcc=5 \t Ocena klasyfikatora: 6.67 %\n",
      "n_mfcc=6 \t Ocena klasyfikatora: 6.00 %\n",
      "n_mfcc=7 \t Ocena klasyfikatora: 9.33 %\n",
      "n_mfcc=8 \t Ocena klasyfikatora: 8.67 %\n",
      "n_mfcc=9 \t Ocena klasyfikatora: 11.33 %\n",
      "n_mfcc=10 \t Ocena klasyfikatora: 8.33 %\n",
      "n_mfcc=11 \t Ocena klasyfikatora: 8.00 %\n",
      "n_mfcc=12 \t Ocena klasyfikatora: 8.67 %\n",
      "n_mfcc=13 \t Ocena klasyfikatora: 7.00 %\n",
      "n_mfcc=14 \t Ocena klasyfikatora: 6.67 %\n",
      "n_mfcc=15 \t Ocena klasyfikatora: 6.67 %\n",
      "n_mfcc=16 \t Ocena klasyfikatora: 8.67 %\n",
      "n_mfcc=17 \t Ocena klasyfikatora: 8.67 %\n",
      "n_mfcc=18 \t Ocena klasyfikatora: 9.67 %\n",
      "n_mfcc=19 \t Ocena klasyfikatora: 9.33 %\n",
      "n_mfcc=20 \t Ocena klasyfikatora: 10.00 %\n",
      "n_mfcc=21 \t Ocena klasyfikatora: 8.67 %\n",
      "n_mfcc=22 \t Ocena klasyfikatora: 8.00 %\n",
      "n_mfcc=23 \t Ocena klasyfikatora: 8.00 %\n",
      "n_mfcc=24 \t Ocena klasyfikatora: 7.33 %\n",
      "n_mfcc=25 \t Ocena klasyfikatora: 6.33 %\n",
      "n_mfcc=26 \t Ocena klasyfikatora: 5.67 %\n",
      "n_mfcc=27 \t Ocena klasyfikatora: 5.67 %\n",
      "n_mfcc=28 \t Ocena klasyfikatora: 5.33 %\n",
      "n_mfcc=29 \t Ocena klasyfikatora: 5.33 %\n",
      "n_mfcc=30 \t Ocena klasyfikatora: 6.00 %\n",
      "n_mfcc=31 \t Ocena klasyfikatora: 5.33 %\n",
      "n_mfcc=32 \t Ocena klasyfikatora: 5.33 %\n",
      "n_mfcc=33 \t Ocena klasyfikatora: 6.00 %\n",
      "n_mfcc=34 \t Ocena klasyfikatora: 6.00 %\n",
      "n_mfcc=35 \t Ocena klasyfikatora: 5.33 %\n",
      "n_mfcc=36 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=37 \t Ocena klasyfikatora: 6.00 %\n",
      "n_mfcc=38 \t Ocena klasyfikatora: 5.33 %\n",
      "n_mfcc=39 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=40 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=41 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=42 \t Ocena klasyfikatora: 5.67 %\n",
      "n_mfcc=43 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=44 \t Ocena klasyfikatora: 6.00 %\n",
      "n_mfcc=45 \t Ocena klasyfikatora: 5.67 %\n",
      "n_mfcc=46 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=47 \t Ocena klasyfikatora: 3.33 %\n",
      "n_mfcc=48 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=49 \t Ocena klasyfikatora: 5.67 %\n",
      "n_mfcc=50 \t Ocena klasyfikatora: 5.33 %\n",
      "n_mfcc=51 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=52 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=53 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=54 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=55 \t Ocena klasyfikatora: 3.00 %\n",
      "n_mfcc=56 \t Ocena klasyfikatora: 3.00 %\n",
      "n_mfcc=57 \t Ocena klasyfikatora: 3.00 %\n",
      "n_mfcc=58 \t Ocena klasyfikatora: 3.00 %\n",
      "n_mfcc=59 \t Ocena klasyfikatora: 3.33 %\n",
      "n_mfcc=60 \t Ocena klasyfikatora: 3.33 %\n",
      "n_mfcc=61 \t Ocena klasyfikatora: 3.33 %\n",
      "n_mfcc=62 \t Ocena klasyfikatora: 2.67 %\n",
      "n_mfcc=63 \t Ocena klasyfikatora: 3.67 %\n",
      "n_mfcc=64 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=65 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=66 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=67 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=68 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=69 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=70 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=71 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=72 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=73 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=74 \t Ocena klasyfikatora: 3.00 %\n",
      "n_mfcc=75 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=76 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=77 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=78 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=79 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=80 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=81 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=82 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=83 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=84 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=85 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=86 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=87 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=88 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=89 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=90 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=91 \t Ocena klasyfikatora: 3.67 %\n",
      "n_mfcc=92 \t Ocena klasyfikatora: 4.00 %\n",
      "n_mfcc=93 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=94 \t Ocena klasyfikatora: 4.67 %\n",
      "n_mfcc=95 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=96 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=97 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=98 \t Ocena klasyfikatora: 4.33 %\n",
      "n_mfcc=99 \t Ocena klasyfikatora: 5.00 %\n",
      "n_mfcc=100 \t Ocena klasyfikatora: 4.67 %\n",
      "best_mfcc = 9 \t best_quality = 11.333333333333332\n"
     ]
    }
   ],
   "source": [
    "# 1. Ekstrakcja cech z próbek\n",
    "# Lista ekstraktorów cech: https://librosa.github.io/librosa/feature.html\n",
    "\n",
    "# ścieżka z folderami z nagraniami - próbki:\n",
    "train_audio_path = 'C:/Users/Aayli/Documents/Delete'\n",
    "commands = os.listdir(train_audio_path);  \n",
    "\n",
    "# użyjemy MFCC, tj. Mel-frequency cepstral coefficients\n",
    "# jednym z parametrów jest liczba wyjściowych współczynników:\n",
    "n_mfcc = 40\n",
    "qualities = []\n",
    "\n",
    "# wczytujemy każde nagranie, wykonujemy ekstrakcję i zapamiętujemy jej wynik\n",
    "for n_mfcc in range(1,101):\n",
    "    classes = []\n",
    "    class_size = 100 # użyjemy tylko po kilka danych\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for command in commands:\n",
    "        if command == 'testing_list.txt' or command == 'validation_list.txt' or command == '_background_noise_' or command == 'tmp':\n",
    "            continue\n",
    "        classes.append(command)\n",
    "        sample_num = 0\n",
    "        for file in os.listdir(train_audio_path + '/' + command + '/'):\n",
    "            sample_num += 1\n",
    "            # przykład z MFCC:\n",
    "            # y - waveform, sr - sampling rate, n_mfcc - number of MFCCs to return\n",
    "            y, sr = librosa.load(train_audio_path + '/' + command + '/' + file)\n",
    "            mfcc_seq = librosa.feature.mfcc(y = y, sr = sr, n_mfcc = n_mfcc)\n",
    "            mean_mfcc_seq = []\n",
    "            for feature in mfcc_seq:\n",
    "                mean_mfcc_seq.append(numpy.mean(feature))\n",
    "            samples.append(mean_mfcc_seq)\n",
    "            labels.append(command)\n",
    "            if sample_num == class_size:\n",
    "                break\n",
    "\n",
    "    # warto podglądnąć, dla mniejszych n_mfcc, np. 5 co kryje mfcc_seq i mean_mfcc_seq\n",
    "    \n",
    "    # 2. Wybór danych treningowych i testowych\n",
    "\n",
    "    # Zautomatyzowany i losowy sposób to użycie:\n",
    "    # \"from sklearn.model_selection import train_test_split\" oraz funkcji \"train_test_split()\"\n",
    "\n",
    "    # wybierzmy 10 pierwszych próbek z każdej klasy jako uczące\n",
    "    # oraz kolejne 2 z każdej klasy jako testowe\n",
    "    # uwaga! train_size + test_size NIE może przekroczyć class_size (poprzedni punkt)\n",
    "    train_size = 40\n",
    "    test_size = 10\n",
    "    train_samples = []\n",
    "    train_labels = []\n",
    "    test_samples = []\n",
    "    test_labels = []\n",
    "    for classname in classes:\n",
    "        train_size_index = 0\n",
    "        test_size_index = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == classname and train_size_index < train_size:\n",
    "                train_samples.append(samples[i])\n",
    "                train_labels.append(labels[i])\n",
    "                train_size_index += 1\n",
    "            elif labels[i] == classname and test_size_index < test_size:\n",
    "                test_samples.append(samples[i])\n",
    "                test_labels.append(labels[i])\n",
    "                test_size_index += 1\n",
    "            if train_size_index == train_size and test_size_index == test_size:\n",
    "                break\n",
    "            \n",
    "    # proszę sprawdzić, czy dane zostały wybrane prawidłowo\n",
    "\n",
    "\n",
    "    # 3. Uczenie klasyfikatora danymi treningowymi\n",
    "\n",
    "    # Lista klasyfikatorów: https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/\n",
    "    # Prosty tutorial: https://www.digitalocean.com/community/tutorials/how-to-build-a-machine-learning-classifier-in-python-with-scikit-learn\n",
    "\n",
    "    # skalowanie/normalizacja danych\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_samples)\n",
    "    train_samples = scaler.transform(train_samples)\n",
    "    test_samples = scaler.transform(test_samples)\n",
    "\n",
    "    # uczenie\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    k = 5\n",
    "    classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "    classifier.fit(train_samples, train_labels)\n",
    "\n",
    "\n",
    "    # 4. Klasyfikacja nieznanych próbek\n",
    "    predicted_labels = classifier.predict(test_samples)\n",
    "\n",
    "    # zobaczmy wynik - zakomentować dla dużych zbiorów\n",
    "    # print(test_labels)\n",
    "    # print(predicted_labels)\n",
    "\n",
    "\n",
    "    # 5. Ocena klasyfikatora\n",
    "    # print(test_labels == predicted_labels)\n",
    "    quality = numpy.sum(test_labels == predicted_labels) / len(test_labels) * 100;\n",
    "    print(f'n_mfcc={n_mfcc} \\t Ocena klasyfikatora: %.2f %%' % quality)\n",
    "    qualities.append(quality)\n",
    "\n",
    "n_mfcc_optimal = qualities.index(max(qualities))+1\n",
    "print(f\"best_mfcc = {n_mfcc_optimal} \\t best_quality = {max(qualities)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size=1 \t Ocena klasyfikatora: 2.33 %\n",
      "train_size=2 \t Ocena klasyfikatora: 5.00 %\n",
      "train_size=3 \t Ocena klasyfikatora: 4.67 %\n",
      "train_size=4 \t Ocena klasyfikatora: 6.33 %\n",
      "train_size=5 \t Ocena klasyfikatora: 4.67 %\n",
      "train_size=6 \t Ocena klasyfikatora: 7.33 %\n",
      "train_size=7 \t Ocena klasyfikatora: 8.33 %\n",
      "train_size=8 \t Ocena klasyfikatora: 10.00 %\n",
      "train_size=9 \t Ocena klasyfikatora: 8.67 %\n",
      "train_size=10 \t Ocena klasyfikatora: 10.33 %\n",
      "train_size=11 \t Ocena klasyfikatora: 14.33 %\n",
      "train_size=12 \t Ocena klasyfikatora: 16.00 %\n",
      "train_size=13 \t Ocena klasyfikatora: 13.33 %\n",
      "train_size=14 \t Ocena klasyfikatora: 11.00 %\n",
      "train_size=15 \t Ocena klasyfikatora: 10.67 %\n",
      "train_size=16 \t Ocena klasyfikatora: 10.33 %\n",
      "train_size=17 \t Ocena klasyfikatora: 8.67 %\n",
      "train_size=18 \t Ocena klasyfikatora: 6.00 %\n",
      "train_size=19 \t Ocena klasyfikatora: 6.00 %\n",
      "train_size=20 \t Ocena klasyfikatora: 7.00 %\n",
      "train_size=21 \t Ocena klasyfikatora: 7.67 %\n",
      "train_size=22 \t Ocena klasyfikatora: 8.00 %\n",
      "train_size=23 \t Ocena klasyfikatora: 7.67 %\n",
      "train_size=24 \t Ocena klasyfikatora: 8.67 %\n",
      "train_size=25 \t Ocena klasyfikatora: 8.00 %\n",
      "train_size=26 \t Ocena klasyfikatora: 9.00 %\n",
      "train_size=27 \t Ocena klasyfikatora: 7.00 %\n",
      "train_size=28 \t Ocena klasyfikatora: 6.33 %\n",
      "train_size=29 \t Ocena klasyfikatora: 4.67 %\n",
      "train_size=30 \t Ocena klasyfikatora: 5.00 %\n",
      "train_size=31 \t Ocena klasyfikatora: 6.00 %\n",
      "train_size=32 \t Ocena klasyfikatora: 6.33 %\n",
      "train_size=33 \t Ocena klasyfikatora: 7.67 %\n",
      "train_size=34 \t Ocena klasyfikatora: 7.33 %\n",
      "train_size=35 \t Ocena klasyfikatora: 6.67 %\n",
      "train_size=36 \t Ocena klasyfikatora: 7.00 %\n",
      "train_size=37 \t Ocena klasyfikatora: 9.00 %\n",
      "train_size=38 \t Ocena klasyfikatora: 9.67 %\n",
      "train_size=39 \t Ocena klasyfikatora: 11.67 %\n",
      "train_size=40 \t Ocena klasyfikatora: 11.33 %\n",
      "train_size=41 \t Ocena klasyfikatora: 10.00 %\n",
      "train_size=42 \t Ocena klasyfikatora: 10.00 %\n",
      "train_size=43 \t Ocena klasyfikatora: 9.67 %\n",
      "train_size=44 \t Ocena klasyfikatora: 9.33 %\n",
      "train_size=45 \t Ocena klasyfikatora: 9.67 %\n",
      "train_size=46 \t Ocena klasyfikatora: 9.67 %\n",
      "train_size=47 \t Ocena klasyfikatora: 10.33 %\n",
      "train_size=48 \t Ocena klasyfikatora: 9.00 %\n",
      "train_size=49 \t Ocena klasyfikatora: 10.67 %\n",
      "train_size=50 \t Ocena klasyfikatora: 10.33 %\n",
      "train_size=51 \t Ocena klasyfikatora: 10.33 %\n",
      "train_size=52 \t Ocena klasyfikatora: 12.33 %\n",
      "train_size=53 \t Ocena klasyfikatora: 11.00 %\n",
      "train_size=54 \t Ocena klasyfikatora: 10.67 %\n",
      "train_size=55 \t Ocena klasyfikatora: 12.00 %\n",
      "train_size=56 \t Ocena klasyfikatora: 12.00 %\n",
      "train_size=57 \t Ocena klasyfikatora: 12.00 %\n",
      "train_size=58 \t Ocena klasyfikatora: 12.00 %\n",
      "train_size=59 \t Ocena klasyfikatora: 9.00 %\n",
      "train_size=60 \t Ocena klasyfikatora: 8.33 %\n",
      "train_size=61 \t Ocena klasyfikatora: 8.33 %\n",
      "train_size=62 \t Ocena klasyfikatora: 8.00 %\n",
      "train_size=63 \t Ocena klasyfikatora: 10.00 %\n",
      "train_size=64 \t Ocena klasyfikatora: 8.00 %\n",
      "train_size=65 \t Ocena klasyfikatora: 9.00 %\n",
      "train_size=66 \t Ocena klasyfikatora: 9.67 %\n",
      "train_size=67 \t Ocena klasyfikatora: 11.33 %\n",
      "train_size=68 \t Ocena klasyfikatora: 10.67 %\n",
      "train_size=69 \t Ocena klasyfikatora: 11.00 %\n",
      "train_size=70 \t Ocena klasyfikatora: 10.67 %\n",
      "train_size=71 \t Ocena klasyfikatora: 9.33 %\n",
      "train_size=72 \t Ocena klasyfikatora: 9.33 %\n",
      "train_size=73 \t Ocena klasyfikatora: 10.00 %\n",
      "train_size=74 \t Ocena klasyfikatora: 10.33 %\n",
      "train_size=75 \t Ocena klasyfikatora: 9.67 %\n",
      "train_size=76 \t Ocena klasyfikatora: 10.67 %\n",
      "train_size=77 \t Ocena klasyfikatora: 14.67 %\n",
      "train_size=78 \t Ocena klasyfikatora: 14.33 %\n",
      "train_size=79 \t Ocena klasyfikatora: 12.67 %\n",
      "train_size=80 \t Ocena klasyfikatora: 13.67 %\n",
      "train_size=81 \t Ocena klasyfikatora: 13.67 %\n",
      "train_size=82 \t Ocena klasyfikatora: 14.33 %\n",
      "train_size=83 \t Ocena klasyfikatora: 12.67 %\n",
      "train_size=84 \t Ocena klasyfikatora: 12.67 %\n",
      "train_size=85 \t Ocena klasyfikatora: 13.00 %\n",
      "train_size=86 \t Ocena klasyfikatora: 11.67 %\n",
      "train_size=87 \t Ocena klasyfikatora: 9.33 %\n",
      "train_size=88 \t Ocena klasyfikatora: 10.00 %\n",
      "train_size=89 \t Ocena klasyfikatora: 9.00 %\n",
      "train_size=90 \t Ocena klasyfikatora: 9.33 %\n",
      "train_size = 12 \t best_quality = 16.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Ekstrakcja cech z próbek\n",
    "# Lista ekstraktorów cech: https://librosa.github.io/librosa/feature.html\n",
    "\n",
    "# ścieżka z folderami z nagraniami - próbki:\n",
    "train_audio_path = 'C:/Users/Aayli/Documents/Delete'\n",
    "commands = os.listdir(train_audio_path);  \n",
    "\n",
    "# użyjemy MFCC, tj. Mel-frequency cepstral coefficients\n",
    "# jednym z parametrów jest liczba wyjściowych współczynników:\n",
    "n_mfcc = n_mfcc_optimal\n",
    "qualities = []\n",
    "\n",
    "# wczytujemy każde nagranie, wykonujemy ekstrakcję i zapamiętujemy jej wynik\n",
    "for train_size in range(1,91):\n",
    "    classes = []\n",
    "    class_size = 100 # użyjemy tylko po kilka danych\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for command in commands:\n",
    "        if command == 'testing_list.txt' or command == 'validation_list.txt' or command == '_background_noise_' or command == 'tmp':\n",
    "            continue\n",
    "        classes.append(command)\n",
    "        sample_num = 0\n",
    "        for file in os.listdir(train_audio_path + '/' + command + '/'):\n",
    "            sample_num += 1\n",
    "            # przykład z MFCC:\n",
    "            # y - waveform, sr - sampling rate, n_mfcc - number of MFCCs to return\n",
    "            y, sr = librosa.load(train_audio_path + '/' + command + '/' + file)\n",
    "            mfcc_seq = librosa.feature.mfcc(y = y, sr = sr, n_mfcc = n_mfcc)\n",
    "            mean_mfcc_seq = []\n",
    "            for feature in mfcc_seq:\n",
    "                mean_mfcc_seq.append(numpy.mean(feature))\n",
    "            samples.append(mean_mfcc_seq)\n",
    "            labels.append(command)\n",
    "            if sample_num == class_size:\n",
    "                break\n",
    "\n",
    "    # warto podglądnąć, dla mniejszych n_mfcc, np. 5 co kryje mfcc_seq i mean_mfcc_seq\n",
    "\n",
    "    # 2. Wybór danych treningowych i testowych\n",
    "\n",
    "    # Zautomatyzowany i losowy sposób to użycie:\n",
    "    # \"from sklearn.model_selection import train_test_split\" oraz funkcji \"train_test_split()\"\n",
    "\n",
    "    # wybierzmy 10 pierwszych próbek z każdej klasy jako uczące\n",
    "    # oraz kolejne 2 z każdej klasy jako testowe\n",
    "    # uwaga! train_size + test_size NIE może przekroczyć class_size (poprzedni punkt)\n",
    "#     train_size = 40\n",
    "    test_size = 10\n",
    "    train_samples = []\n",
    "    train_labels = []\n",
    "    test_samples = []\n",
    "    test_labels = []\n",
    "    for classname in classes:\n",
    "        train_size_index = 0\n",
    "        test_size_index = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == classname and train_size_index < train_size:\n",
    "                train_samples.append(samples[i])\n",
    "                train_labels.append(labels[i])\n",
    "                train_size_index += 1\n",
    "            elif labels[i] == classname and test_size_index < test_size:\n",
    "                test_samples.append(samples[i])\n",
    "                test_labels.append(labels[i])\n",
    "                test_size_index += 1\n",
    "            if train_size_index == train_size and test_size_index == test_size:\n",
    "                break\n",
    "            \n",
    "\n",
    "    # 3. Uczenie klasyfikatora danymi treningowymi\n",
    "\n",
    "    # Lista klasyfikatorów: https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/\n",
    "    # Prosty tutorial: https://www.digitalocean.com/community/tutorials/how-to-build-a-machine-learning-classifier-in-python-with-scikit-learn\n",
    "\n",
    "    # skalowanie/normalizacja danych\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_samples)\n",
    "    train_samples = scaler.transform(train_samples)\n",
    "    test_samples = scaler.transform(test_samples)\n",
    "\n",
    "    # uczenie\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    k = 5\n",
    "    classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "    classifier.fit(train_samples, train_labels)\n",
    "\n",
    "\n",
    "    # 4. Klasyfikacja nieznanych próbek\n",
    "    predicted_labels = classifier.predict(test_samples)\n",
    "\n",
    "    # zobaczmy wynik - zakomentować dla dużych zbiorów\n",
    "    # print(test_labels)\n",
    "    # print(predicted_labels)\n",
    "\n",
    "\n",
    "    # 5. Ocena klasyfikatora\n",
    "    # print(test_labels == predicted_labels)\n",
    "    quality = numpy.sum(test_labels == predicted_labels) / len(test_labels) * 100;\n",
    "    print(f'train_size={train_size} \\t Ocena klasyfikatora: %.2f %%' % quality)\n",
    "    qualities.append(quality)\n",
    "\n",
    "train_size_optimal = qualities.index(max(qualities))+1\n",
    "print(f\"train_size = {train_size_optimal} \\t best_quality = {max(qualities)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optiomal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 \t Ocena klasyfikatora: 17.00 %\n",
      "k=2 \t Ocena klasyfikatora: 15.67 %\n",
      "k=3 \t Ocena klasyfikatora: 17.00 %\n",
      "k=4 \t Ocena klasyfikatora: 15.00 %\n",
      "k=5 \t Ocena klasyfikatora: 16.00 %\n",
      "k=6 \t Ocena klasyfikatora: 14.33 %\n",
      "k=7 \t Ocena klasyfikatora: 13.67 %\n",
      "k=8 \t Ocena klasyfikatora: 14.33 %\n",
      "k=9 \t Ocena klasyfikatora: 13.33 %\n",
      "k=10 \t Ocena klasyfikatora: 13.00 %\n",
      "k = 1 \t best_quality = 17.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Ekstrakcja cech z próbek\n",
    "# Lista ekstraktorów cech: https://librosa.github.io/librosa/feature.html\n",
    "\n",
    "# ścieżka z folderami z nagraniami - próbki:\n",
    "train_audio_path = 'C:/Users/Aayli/Documents/Delete'\n",
    "commands = os.listdir(train_audio_path);  \n",
    "\n",
    "# użyjemy MFCC, tj. Mel-frequency cepstral coefficients\n",
    "# jednym z parametrów jest liczba wyjściowych współczynników:\n",
    "n_mfcc = n_mfcc_optimal\n",
    "qualities = []\n",
    "\n",
    "# wczytujemy każde nagranie, wykonujemy ekstrakcję i zapamiętujemy jej wynik\n",
    "for k in range(1,11):\n",
    "    classes = []\n",
    "    class_size = 100 # użyjemy tylko po kilka danych\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for command in commands:\n",
    "        if command == 'testing_list.txt' or command == 'validation_list.txt' or command == '_background_noise_' or command == 'tmp':\n",
    "            continue\n",
    "        classes.append(command)\n",
    "        sample_num = 0\n",
    "        for file in os.listdir(train_audio_path + '/' + command + '/'):\n",
    "            sample_num += 1\n",
    "            # przykład z MFCC:\n",
    "            # y - waveform, sr - sampling rate, n_mfcc - number of MFCCs to return\n",
    "            y, sr = librosa.load(train_audio_path + '/' + command + '/' + file)\n",
    "            mfcc_seq = librosa.feature.mfcc(y = y, sr = sr, n_mfcc = n_mfcc)\n",
    "            mean_mfcc_seq = []\n",
    "            for feature in mfcc_seq:\n",
    "                mean_mfcc_seq.append(numpy.mean(feature))\n",
    "            samples.append(mean_mfcc_seq)\n",
    "            labels.append(command)\n",
    "            if sample_num == class_size:\n",
    "                break\n",
    "\n",
    "    # warto podglądnąć, dla mniejszych n_mfcc, np. 5 co kryje mfcc_seq i mean_mfcc_seq\n",
    "    \n",
    "    # 2. Wybór danych treningowych i testowych\n",
    "\n",
    "    # Zautomatyzowany i losowy sposób to użycie:\n",
    "    # \"from sklearn.model_selection import train_test_split\" oraz funkcji \"train_test_split()\"\n",
    "\n",
    "    # wybierzmy 10 pierwszych próbek z każdej klasy jako uczące\n",
    "    # oraz kolejne 2 z każdej klasy jako testowe\n",
    "    # uwaga! train_size + test_size NIE może przekroczyć class_size (poprzedni punkt)\n",
    "    train_size = train_size_optimal\n",
    "    test_size = 10\n",
    "    train_samples = []\n",
    "    train_labels = []\n",
    "    test_samples = []\n",
    "    test_labels = []\n",
    "    for classname in classes:\n",
    "        train_size_index = 0\n",
    "        test_size_index = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == classname and train_size_index < train_size:\n",
    "                train_samples.append(samples[i])\n",
    "                train_labels.append(labels[i])\n",
    "                train_size_index += 1\n",
    "            elif labels[i] == classname and test_size_index < test_size:\n",
    "                test_samples.append(samples[i])\n",
    "                test_labels.append(labels[i])\n",
    "                test_size_index += 1\n",
    "            if train_size_index == train_size and test_size_index == test_size:\n",
    "                break\n",
    "            \n",
    "\n",
    "    # 3. Uczenie klasyfikatora danymi treningowymi\n",
    "\n",
    "    # Lista klasyfikatorów: https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/\n",
    "    # Prosty tutorial: https://www.digitalocean.com/community/tutorials/how-to-build-a-machine-learning-classifier-in-python-with-scikit-learn\n",
    "\n",
    "    # skalowanie/normalizacja danych\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_samples)\n",
    "    train_samples = scaler.transform(train_samples)\n",
    "    test_samples = scaler.transform(test_samples)\n",
    "\n",
    "    # uczenie\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "#     k = 5\n",
    "    classifier = KNeighborsClassifier(n_neighbors = k)\n",
    "    classifier.fit(train_samples, train_labels)\n",
    "\n",
    "\n",
    "    # 4. Klasyfikacja nieznanych próbek\n",
    "    predicted_labels = classifier.predict(test_samples)\n",
    "\n",
    "    # zobaczmy wynik - zakomentować dla dużych zbiorów\n",
    "    # print(test_labels)\n",
    "    # print(predicted_labels)\n",
    "\n",
    "\n",
    "    # 5. Ocena klasyfikatora\n",
    "    # print(test_labels == predicted_labels)\n",
    "    quality = numpy.sum(test_labels == predicted_labels) / len(test_labels) * 100;\n",
    "    print(f'k={k} \\t Ocena klasyfikatora: %.2f %%' % quality)\n",
    "    qualities.append(quality)\n",
    "\n",
    "k_optimal = qualities.index(max(qualities))+1\n",
    "print(f\"k = {k_optimal} \\t best_quality = {max(qualities)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
